{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNV2 - Model Training",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ian-mcnair/ForageSnap/blob/master/MNV2_Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e05ACj9WKV5h",
        "colab_type": "text"
      },
      "source": [
        "# Import Statements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMq8Zd0M7FFB",
        "colab_type": "text"
      },
      "source": [
        "Installs all needed packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJVG0ZoVxFQr",
        "colab_type": "code",
        "outputId": "ff0b0637-4fdb-49f6-fca9-2d51cba7e2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install tf-nightly-gpu-2.0-preview\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-gpu-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/61/30a3996dcc99cdb151b6f2c2f7702629514e638e161eb1677897d80de959/tf_nightly_gpu_2.0_preview-2.0.0.dev20190731-cp36-cp36m-manylinux1_x86_64.whl (378.9MB)\n",
            "\u001b[K     |████████████████████████████████| 378.9MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.16.4)\n",
            "Collecting opt-einsum>=2.3.2 (from tf-nightly-gpu-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 22.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.12.0)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-gpu-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/ab/ac8592c015272baf0cdf9ed6f19f69dd7c70f7f5fe293f9b68babf848eb8/tensorflow_estimator_2.0_preview-1.14.0.dev2019073000-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.33.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.11.2)\n",
            "Collecting tb-nightly<1.16.0a0,>=1.15.0a0 (from tf-nightly-gpu-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/80/cdc1f6f645bea9108807a54c7119f98cfb81b8f183aea7df8ab2b5a93630/tb_nightly-1.15.0a20190731-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-gpu-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-gpu-2.0-preview) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-gpu-2.0-preview) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-gpu-2.0-preview) (3.1.1)\n",
            "Building wheels for collected packages: opt-einsum\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
            "Successfully built opt-einsum\n",
            "Installing collected packages: opt-einsum, tensorflow-estimator-2.0-preview, tb-nightly, tf-nightly-gpu-2.0-preview\n",
            "Successfully installed opt-einsum-2.3.2 tb-nightly-1.15.0a20190731 tensorflow-estimator-2.0-preview-1.14.0.dev2019073000 tf-nightly-gpu-2.0-preview-2.0.0.dev20190731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8VW3_7X90En",
        "colab_type": "code",
        "outputId": "28ccd137-168f-442c-c8cb-a55f8acb121c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm5rq5WGxY68",
        "colab_type": "text"
      },
      "source": [
        "# Creating Image Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJTS1PjE7LMT",
        "colab_type": "text"
      },
      "source": [
        "Base directory is where all the files are located in our shared Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wl6ybOuxVar",
        "colab_type": "code",
        "outputId": "e7981437-53ae-421e-d862-e87c52ff3579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "base_dir = '/content/drive/My Drive/Project FORSCAN/Datasets/PoC Images'\n",
        "base_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Project FORSCAN/Datasets/PoC Images'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhbfCz9mxV1j",
        "colab_type": "code",
        "outputId": "754115ca-e35f-4a66-b9c3-4523245ad7ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split = 0.2,\n",
        "    rotation_range = 45,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training',\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation',\n",
        "    shuffle = True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7112 images belonging to 14 classes.\n",
            "Found 1769 images belonging to 14 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7b1a2d59-1566-452c-c835-15fb6d49b78b",
        "id": "deItUgxtOYec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 224, 224, 3), (64, 14))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTK66aS_0Wtu",
        "colab_type": "text"
      },
      "source": [
        "# Making the Labels.txt File for Later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Mzzb2KxVw7",
        "colab_type": "code",
        "outputId": "945003b4-ac8d-47b1-d6a3-31f0fd62b85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Edible: Alligator Juniper': 0, 'Edible: Asparagus': 1, 'Edible: Bamboo': 2, 'Edible: Berries': 3, 'Edible: Dandelion': 4, 'Edible: Pecans': 5, 'Edible: Rosemary': 6, 'Edible: Southern Magnolia': 7, 'Harmful: Laurel Family': 8, 'Harmful: Nightshade': 9, 'Harmful: Poison Ivy': 10, 'Harmful: Poison Oak': 11, 'Harmful: Poison Sumac': 12, 'Harmful: Yew': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fBYI-rBxVvj",
        "colab_type": "code",
        "outputId": "150735b1-681c-4e70-eae8-23436f25b587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "!cat labels.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Edible: Alligator Juniper\n",
            "Edible: Asparagus\n",
            "Edible: Bamboo\n",
            "Edible: Berries\n",
            "Edible: Dandelion\n",
            "Edible: Pecans\n",
            "Edible: Rosemary\n",
            "Edible: Southern Magnolia\n",
            "Harmful: Laurel Family\n",
            "Harmful: Nightshade\n",
            "Harmful: Poison Ivy\n",
            "Harmful: Poison Oak\n",
            "Harmful: Poison Sumac\n",
            "Harmful: Yew"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsRGzmlU0bAk",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_7YfhhtxVtX",
        "colab_type": "code",
        "outputId": "4791ac75-a0ab-498b-8fe0-069c0e66cac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                          include_top = False,\n",
        "                                          weights = 'imagenet')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-pmCSHs0eaY",
        "colab_type": "text"
      },
      "source": [
        "You can make the model trainable of freeze it. You can also specifiy at which layer you want to enable training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bqobftNyxcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iSK9NHM0mfV",
        "colab_type": "text"
      },
      "source": [
        "# Recreating the Output Layer\n",
        "num_classes should match number of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEI67m1myxaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 14\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax') # The layer amount needs to match the classes\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrwgW8J70vbQ",
        "colab_type": "text"
      },
      "source": [
        "# Compiling The Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSv8FKwQyxYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-4, decay = 1e-5 ), # 1e-4\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0tMY7xiyxTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYZrt3rFxVqn",
        "colab_type": "code",
        "outputId": "987cb536-606f-48a0-ceb1-3a03304a097f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable variables = 160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT506NC9005a",
        "colab_type": "text"
      },
      "source": [
        "# Setting Up Checkpoints to save the model as it trains"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-h9uN5A4sp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This currently causes a known error when trying to retrain\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath=\"/content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, \n",
        "                             monitor='val_accuracy', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjx58BHt05dj",
        "colab_type": "text"
      },
      "source": [
        "# Loading a Model instead of creating a new one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pOZZbJ89rQ2",
        "colab_type": "code",
        "outputId": "3e0261a9-d585-48a0-8d0c-98300bb6f478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Use only when needed\n",
        "# Doesn't work. Raises errors about needing a placeholder\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-09-0.75.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0731 13:41:52.055122 140562483439488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1423: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0731 13:42:18.652628 140562483439488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:468: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Apply a constraint manually following the optimizer update step.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPFcUU4mPNFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgy0x6GAWxHJ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahq0sdl7zIu8",
        "colab_type": "code",
        "outputId": "e20f165a-d443-4fa7-aba4-d16ff9260daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 15\n",
        "\n",
        "history = model.fit_generator(train_generator, \n",
        "                    epochs=epochs, \n",
        "                    validation_data=val_generator,\n",
        "                    callbacks = callbacks_list,\n",
        "                    shuffle = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "111/112 [============================>.] - ETA: 22s - loss: 0.2190 - accuracy: 0.9268\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70831, saving model to /content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-01-0.71.hdf5\n",
            "112/112 [==============================] - 3133s 28s/step - loss: 0.2211 - accuracy: 0.9258 - val_loss: 1.4008 - val_accuracy: 0.7083\n",
            "Epoch 2/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1910 - accuracy: 0.9364\n",
            "Epoch 00002: val_accuracy did not improve from 0.70831\n",
            "112/112 [==============================] - 2440s 22s/step - loss: 0.1909 - accuracy: 0.9366 - val_loss: 1.6468 - val_accuracy: 0.6750\n",
            "Epoch 3/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1905 - accuracy: 0.9407\n",
            "Epoch 00003: val_accuracy improved from 0.70831 to 0.71792, saving model to /content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-03-0.72.hdf5\n",
            "112/112 [==============================] - 2439s 22s/step - loss: 0.1904 - accuracy: 0.9409 - val_loss: 1.2575 - val_accuracy: 0.7179\n",
            "Epoch 4/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1873 - accuracy: 0.9401\n",
            "Epoch 00004: val_accuracy did not improve from 0.71792\n",
            "112/112 [==============================] - 2442s 22s/step - loss: 0.1868 - accuracy: 0.9402 - val_loss: 1.2937 - val_accuracy: 0.7151\n",
            "Epoch 5/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1572 - accuracy: 0.9496\n",
            "Epoch 00005: val_accuracy did not improve from 0.71792\n",
            "112/112 [==============================] - 2435s 22s/step - loss: 0.1565 - accuracy: 0.9498 - val_loss: 1.3733 - val_accuracy: 0.7168\n",
            "Epoch 6/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1327 - accuracy: 0.9553\n",
            "Epoch 00006: val_accuracy improved from 0.71792 to 0.72018, saving model to /content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-06-0.72.hdf5\n",
            "112/112 [==============================] - 2437s 22s/step - loss: 0.1326 - accuracy: 0.9554 - val_loss: 1.4192 - val_accuracy: 0.7202\n",
            "Epoch 7/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1399 - accuracy: 0.9532\n",
            "Epoch 00007: val_accuracy improved from 0.72018 to 0.74336, saving model to /content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-07-0.74.hdf5\n",
            "112/112 [==============================] - 2462s 22s/step - loss: 0.1394 - accuracy: 0.9532 - val_loss: 1.3416 - val_accuracy: 0.7434\n",
            "Epoch 8/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1418 - accuracy: 0.9547\n",
            "Epoch 00008: val_accuracy did not improve from 0.74336\n",
            "112/112 [==============================] - 2450s 22s/step - loss: 0.1409 - accuracy: 0.9550 - val_loss: 1.3577 - val_accuracy: 0.7264\n",
            "Epoch 9/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1291 - accuracy: 0.9574\n",
            "Epoch 00009: val_accuracy improved from 0.74336 to 0.75353, saving model to /content/drive/My Drive/Project FORSCAN/Models/Checkpoints/MBNV2CheckpointsIan1e-5Decay-7.30-10am9pm-09-0.75.hdf5\n",
            "112/112 [==============================] - 2437s 22s/step - loss: 0.1289 - accuracy: 0.9575 - val_loss: 1.2990 - val_accuracy: 0.7535\n",
            "Epoch 10/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1028 - accuracy: 0.9655\n",
            "Epoch 00010: val_accuracy did not improve from 0.75353\n",
            "112/112 [==============================] - 2455s 22s/step - loss: 0.1033 - accuracy: 0.9654 - val_loss: 1.5373 - val_accuracy: 0.7230\n",
            "Epoch 11/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1060 - accuracy: 0.9641\n",
            "Epoch 00011: val_accuracy did not improve from 0.75353\n",
            "112/112 [==============================] - 2430s 22s/step - loss: 0.1055 - accuracy: 0.9643 - val_loss: 1.4963 - val_accuracy: 0.7332\n",
            "Epoch 12/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1017 - accuracy: 0.9677\n",
            "Epoch 00012: val_accuracy did not improve from 0.75353\n",
            "112/112 [==============================] - 2426s 22s/step - loss: 0.1020 - accuracy: 0.9675 - val_loss: 1.4045 - val_accuracy: 0.7428\n",
            "Epoch 13/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.1243 - accuracy: 0.9613\n",
            "Epoch 00013: val_accuracy did not improve from 0.75353\n",
            "112/112 [==============================] - 2423s 22s/step - loss: 0.1251 - accuracy: 0.9611 - val_loss: 1.6512 - val_accuracy: 0.7015\n",
            "Epoch 14/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.0881 - accuracy: 0.9705\n",
            "Epoch 00014: val_accuracy did not improve from 0.75353\n",
            "112/112 [==============================] - 2435s 22s/step - loss: 0.0875 - accuracy: 0.9708 - val_loss: 1.4401 - val_accuracy: 0.7366\n",
            "Epoch 15/15\n",
            "111/112 [============================>.] - ETA: 20s - loss: 0.0760 - accuracy: 0.9752\n",
            "Epoch 00015: val_accuracy did not improve from 0.75353\n",
            "112/112 [==============================] - 2429s 22s/step - loss: 0.0837 - accuracy: 0.9748 - val_loss: 1.5840 - val_accuracy: 0.7304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DAM-epRpHGA",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy Histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9s3e35nzIre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "# plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "# plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzXQjZDRp0Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving, Exporting, and Downloading Files needed for Android"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTAb-hN2zIoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model_dir = 'save/fine_tuning'\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvPUVzmkzIlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('model.tflite')\n",
        "files.download('labels.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}